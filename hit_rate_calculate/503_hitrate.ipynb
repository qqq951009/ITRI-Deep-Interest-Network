{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM,DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import keras\n",
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    "def load_variable(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "gid_dict = load_variable('/home/jovyan/dataset/gid_dict')\n",
    "gid_list = load_variable('/home/jovyan/dataset/gid_list')#len = 1739595 #4月的所有gid\n",
    "df_val = pd.read_csv('/home/jovyan/dataset/validate_folder/503val.csv')\n",
    "df_candidate = load_variable('/home/jovyan/dataset/original_candidate_itemset/0503_candidate_itemset')#len = 1422941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:5507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888968\n"
     ]
    }
   ],
   "source": [
    "def clean_candidate(df):#舊方法刪完後的結果(不存在就刪掉)\n",
    "    df = df[df['gid'].isin(gid_list)]\n",
    "    df.candidate_items = df.candidate_items.apply(lambda x:x.split(','))\n",
    "    df = df.explode('candidate_items', ignore_index=True)\n",
    "    df = df[df['candidate_items'].isin(gid_list)]#推薦清單 candidate_item清掉不在4/1-4/30的商品\n",
    "    df.gid = df.gid.apply(lambda x:gid_dict[x])\n",
    "    df.candidate_items = df.candidate_items.apply(lambda x:gid_dict[x])\n",
    "    df = df.groupby(['gid']).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    df = df[df.candidate_items.apply(lambda x:len(x)) >15]\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "df_candidate = clean_candidate(df_candidate)#888968\n",
    "#給原本的rank一個分數\n",
    "df_candidate['original_score'] = df_candidate.candidate_items.apply(lambda x:list(np.arange(1,0,-1/len(x))))\n",
    "print(len(df_candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df5_all = load_variable('/home/jovyan/dataset/df5_all')\n",
    "df_uid = df5_all[df5_all['uid'] != 'unknow']\n",
    "df_session = df5_all[df5_all['uid'] == 'unknow']\n",
    "#對uid和session做編碼\n",
    "lbe = LabelEncoder()\n",
    "for i in ['uid']:\n",
    "    df_uid['uid_encode'] = lbe.fit_transform(df_uid[i])\n",
    "    df_uid['uid_encode'] = df_uid['uid_encode'].apply(lambda x:x+1)\n",
    "for i in ['ven_session']:\n",
    "    df_session['session_encode'] = lbe.fit_transform(df_session[i])\n",
    "    df_session['session_encode'] = df_session['session_encode'].apply(lambda x:x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#製作uid和session對應id的dictionary\n",
    "uid_encode_unique = df_uid[['uid','uid_encode']].sort_values('uid_encode').uid_encode.unique()\n",
    "uid_unique = df_uid[['uid','uid_encode']].sort_values('uid_encode').uid.unique()\n",
    "uid_dict = {}\n",
    "for i in zip(uid_encode_unique,uid_unique):\n",
    "    uid_dict[i[1]] = i[0]\n",
    "session_encode_unique = df_session[['ven_session','session_encode']].sort_values('session_encode').session_encode.unique()\n",
    "session_unique = df_session[['ven_session','session_encode']].sort_values('session_encode').ven_session.unique()\n",
    "session_dict = {}\n",
    "for i in zip(session_encode_unique,session_unique):\n",
    "    session_dict[i[1]] = i[0]\n",
    "session_dict[0] = 0\n",
    "uid_dict[0] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#抓5/3的weblog出來，後面會用來找對應uid/session的clickstream\n",
    "df_uid5 = df_uid[df_uid['month'] == 53]\n",
    "df_session5 = df_session[df_session['month'] == 53]\n",
    "df_uid5.uid = df_uid5.uid.apply(lambda x:uid_dict[x])\n",
    "df_session5.ven_session = df_session5.ven_session.apply(lambda x:session_dict[x])\n",
    "df_session5 = df_session5.drop(columns = ['uid','ven_guid'])\n",
    "df_uid5 = df_uid5.drop(columns=['ven_guid','ven_session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90823, 67392)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5/3的validation分成有uid和session(沒uid的)\n",
    "df_val_session = df_val[df_val.uid.isna()]\n",
    "df_val_uid = df_val[~df_val.uid.isna()]\n",
    "len(df_val_session),len(df_val_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把gid、uid和session轉成對應id\n",
    "df_val_session.ven_session = df_val_session.ven_session.apply(lambda x:session_dict[x])\n",
    "df_val_uid.uid = df_val_uid.uid.apply(lambda x:uid_dict[x])\n",
    "df_val_session.gid = df_val_session.gid.apply(lambda x:gid_dict[x])\n",
    "df_val_uid.gid = df_val_uid.gid.apply(lambda x:gid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "#在validation set再加上該row uid/session在weblog的clickstream\n",
    "def process(df_val,df,idname):\n",
    "    hist = []\n",
    "    id_list = df_val[idname].unique().tolist()\n",
    "    for i in id_list:\n",
    "        tempdf = df[df[idname] == i]\n",
    "        tempdf_copy = df[df[idname] == i]\n",
    "        gid_list = df_val[df_val[idname] == i].gid.tolist()\n",
    "        for j in gid_list:\n",
    "            index = tempdf[tempdf.gid_encode == j].index[0]\n",
    "            tempdf = tempdf.drop(index)\n",
    "            hist.append(tempdf_copy.loc[:index].gid_encode.tolist())\n",
    "    df_val['hist'] = hist\n",
    "    return df_val\n",
    "df_val_session = process(df_val_session,df_session5,'ven_session')\n",
    "df_val_uid = process(df_val_uid,df_uid5,'uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59955 47915\n"
     ]
    }
   ],
   "source": [
    "#在validation set中加入該row的gid對應candidate_itesmset的candidate_item(gid)\n",
    "result_session = pd.merge(df_candidate,df_val_session,how = 'inner',on = ['gid'])\n",
    "result_uid = pd.merge(df_candidate,df_val_uid,how = 'inner',on = ['gid'])\n",
    "result_session = result_session[['ven_session','gid','hist','next_gid','candidate_items','original_score']]\n",
    "result_uid = result_uid[['uid','gid','hist','next_gid','candidate_items','original_score']]\n",
    "result_session = result_session.sort_values('ven_session')\n",
    "result_uid = result_uid.sort_values('uid')\n",
    "result_session.next_gid = result_session.next_gid.apply(lambda x:gid_dict[x])\n",
    "result_uid.next_gid = result_uid.next_gid.apply(lambda x:gid_dict[x])\n",
    "#每個row都給他一個flag\n",
    "result_session['flag'] = list(range(1,len(result_session)+1))\n",
    "result_uid['flag'] = list(range(1,len(result_uid)+1))\n",
    "print(len(result_session),len(result_uid)) #(62166, 32886)\n",
    "#展開validation set 以方便之後一一去做預測\n",
    "result_session_explode = result_session.explode(['candidate_items','original_score'], ignore_index=True)\n",
    "result_uid_explode = result_uid.explode(['candidate_items','original_score'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_set(result):\n",
    "    pred_list = []\n",
    "    hist = 0\n",
    "    for i in zip(result['hist'].tolist(),result['candidate_items'].tolist()):\n",
    "        if len(i[0])>100:\n",
    "            pred_list.append((i[0][-100:],i[1],100))\n",
    "        else:\n",
    "            pred_list.append((i[0],i[1],len(i[0])))\n",
    "    return pred_list\n",
    "pred_set_session = create_pred_set(result_session_explode)\n",
    "pred_set_uid = create_pred_set(result_uid_explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_array(pred_set):\n",
    "    hist_g_id = []\n",
    "    g_id = []\n",
    "    seq_length = []\n",
    "    for index, value in enumerate(pred_set):\n",
    "        hist_g_id.append(value[0]) \n",
    "        g_id.append(value[1])\n",
    "        seq_length.append(value[2])\n",
    "    for i in range(len(hist_g_id)):\n",
    "        if len(hist_g_id[i]) < 100:\n",
    "            hist_g_id[i] += (100-len(hist_g_id[i]))*[0]\n",
    "    g_id = np.array(g_id)\n",
    "    hist_g_id = np.array(hist_g_id)\n",
    "    seq_length = np.array(seq_length)\n",
    "    return hist_g_id, g_id, seq_length\n",
    "\n",
    "hist_gid_session, gid_session, seq_length_session = create_predict_array(pred_set_session)\n",
    "hist_gid_uid, gid_uid, seq_length_uid = create_predict_array(pred_set_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uid_pred = {'g_id': gid_uid, \n",
    "        'hist_g_id': hist_gid_uid, \n",
    "        'seq_length': seq_length_uid}\n",
    "x_session_pred = {'g_id': gid_session, \n",
    "        'hist_g_id': hist_gid_session, \n",
    "        'seq_length': seq_length_session}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/1-5/2 predict 5/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"/home/jovyan/dataset/rakuten_model_401_502\")\n",
    "y_uid = model.predict(x_uid_pred)\n",
    "y_session = model.predict(x_session_pred)\n",
    "y_uid = y_uid.reshape(-1).tolist()\n",
    "y_session = y_session.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_uid_explode['score'] = y_uid\n",
    "result_session_explode['score'] = y_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#做ensemble產生新分數: 預測出來的分數佔0.2，原本rank轉換的分數占0.8\n",
    "def cal_new_score(result):\n",
    "    new_score = []\n",
    "    for i in result.iterrows():\n",
    "        new_score.append(0.2*(i[1]['score'])+0.8*(i[1]['original_score']))\n",
    "    result['new_score'] = new_score\n",
    "    result = result.sort_values(['flag','new_score'],ascending = False)\n",
    "    df_output = result.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    return df_output\n",
    "df1 = cal_new_score(result_uid_explode)\n",
    "df2 = cal_new_score(result_session_explode)\n",
    "resultdf = pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21790117734309816 0.31218132937795495 0.3617317141003059\n"
     ]
    }
   ],
   "source": [
    "def hitrate(result,k):\n",
    "    count = 0\n",
    "    for i in result.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count+=1\n",
    "    return count/len(result)\n",
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22440901084638917 0.31512005191434134 0.3627885417632335\n"
     ]
    }
   ],
   "source": [
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using 15 epoch model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4255e63828>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_feature_list = [\"g_id\"]\n",
    "feature_columns = [SparseFeat('g_id', 1870599, embedding_dim=8)]\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('hist_g_id',vocabulary_size=1870599, embedding_dim=8, embedding_name='g_id'), maxlen = 100, length_name='seq_length')]\n",
    "model15 = DIN(feature_columns, behavior_feature_list)\n",
    "model15.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/15epoch/model401_502\")\n",
    "model15.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-c88eeec2c54c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0my_uid15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_uid_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_session15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel15\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_session_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_uid15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_uid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_session15\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_uid_explode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_uid15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "y_uid15 = model15.predict(x_uid_pred)\n",
    "y_session15 = model15.predict(x_session_pred)\n",
    "y_uid15 = y_uid15.reshape(-1).tolist()\n",
    "y_session15 = y_session15.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid15\n",
    "result_session_explode['score'] = y_session15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.14115138592750534 0.22760730508945953 0.2963474552702327\n"
     ]
    }
   ],
   "source": [
    "epoch15_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df1 = epoch15_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df2 = epoch15_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df = pd.concat([epoch15_df1,epoch15_df2],ignore_index=True)\n",
    "top5 = hitrate(epoch15_df,5)\n",
    "top10 = hitrate(epoch15_df,10)\n",
    "top15 = hitrate(epoch15_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using 20 epoch model to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model20 = DIN(feature_columns, behavior_feature_list)\n",
    "model20.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/20epoch/model401_502\")\n",
    "model20.load_weights(latest)\n",
    "\n",
    "y_uid20 = model20.predict(x_uid_pred)\n",
    "y_session20 = model20.predict(x_session_pred)\n",
    "y_uid20 = y_uid20.reshape(-1).tolist()\n",
    "y_session20 = y_session20.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid20\n",
    "result_session_explode['score'] = y_session20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13904700101974599 0.2261147677760267 0.2955872809863725\n"
     ]
    }
   ],
   "source": [
    "epoch20_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df1 = epoch20_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df2 = epoch20_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df = pd.concat([epoch20_df1,epoch20_df2],ignore_index=True)\n",
    "\n",
    "top5 = hitrate(epoch20_df,5)\n",
    "top10 = hitrate(epoch20_df,10)\n",
    "top15 = hitrate(epoch20_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/1-5/3 model predict 5/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model503 = keras.models.load_model(\"/home/jovyan/dataset/rakuten_model_401_503\")\n",
    "y_uid53 = model503.predict(x_uid_pred)\n",
    "y_session53 = model503.predict(x_session_pred)\n",
    "y_uid53 = y_uid53.reshape(-1).tolist()\n",
    "y_session53 = y_session53.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_uid_explode['score'] = y_uid53\n",
    "result_session_explode['score'] = y_session53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_new_score(result):\n",
    "    new_score = []\n",
    "    for i in result.iterrows():\n",
    "        new_score.append(0.2*(i[1]['score'])+0.8*(i[1]['original_score']))\n",
    "    result['new_score'] = new_score\n",
    "    result = result.sort_values(['flag','new_score'],ascending = False)\n",
    "    df_output = result.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    return df_output\n",
    "df3 = cal_new_score(result_uid_explode)\n",
    "df4 = cal_new_score(result_session_explode)\n",
    "resultdf = pd.concat([df3,df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24916102716232502 0.32982293501436916 0.3719755260962269\n"
     ]
    }
   ],
   "source": [
    "def hitrate(result,k):\n",
    "    count = 0\n",
    "    for i in result.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count+=1\n",
    "    return count/len(result)\n",
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2430147399647724 0.3243626587559099 0.3683137109483638\n"
     ]
    }
   ],
   "source": [
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15epoch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model503 = DIN(feature_columns, behavior_feature_list)\n",
    "model503.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/15epoch/model401_503\")\n",
    "model503.load_weights(latest)\n",
    "\n",
    "y_uid15 = model503.predict(x_uid_pred)\n",
    "y_session15 = model503.predict(x_session_pred)\n",
    "y_uid15 = y_uid15.reshape(-1).tolist()\n",
    "y_session15 = y_session15.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid15\n",
    "result_session_explode['score'] = y_session15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23778622415870956 0.32683786038750345 0.37120608139427086\n"
     ]
    }
   ],
   "source": [
    "epoch15_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df1 = epoch15_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df2 = epoch15_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df = pd.concat([epoch15_df1,epoch15_df2],ignore_index=True)\n",
    "top5 = hitrate(epoch15_df,5)\n",
    "top10 = hitrate(epoch15_df,10)\n",
    "top15 = hitrate(epoch15_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20epoch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model503 = DIN(feature_columns, behavior_feature_list)\n",
    "model503.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/20epoch/model401_503\")\n",
    "model503.load_weights(latest)\n",
    "\n",
    "y_uid20 = model503.predict(x_uid_pred)\n",
    "y_session20 = model503.predict(x_session_pred)\n",
    "y_uid20 = y_uid20.reshape(-1).tolist()\n",
    "y_session20 = y_session20.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid20\n",
    "result_session_explode['score'] = y_session20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24078983962176695 0.3284323722999907 0.37171595438954297\n"
     ]
    }
   ],
   "source": [
    "epoch20_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df1 = epoch20_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df2 = epoch20_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df = pd.concat([epoch20_df1,epoch20_df2],ignore_index=True)\n",
    "\n",
    "top5 = hitrate(epoch20_df,5)\n",
    "top10 = hitrate(epoch20_df,10)\n",
    "top15 = hitrate(epoch20_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val1 = df_val_session[df_val_session.gid.isin(df_candidate.gid.tolist())]\n",
    "df_val2 = df_val_uid[df_val_uid.gid.isin(df_candidate.gid.tolist())]\n",
    "df_val_baseline =  pd.concat([df_val1,df_val2],ignore_index=True)\n",
    "df_val_baseline.next_gid = df_val_baseline.next_gid.apply(lambda x:gid_dict[x])\n",
    "df_val_baseline = pd.merge(df_candidate,df_val_baseline,how = 'inner',on = ['gid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_baseline(df,k):\n",
    "    count = 0\n",
    "    for i in df.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count += 1 \n",
    "    return count/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2254843793455085 0.3129785853341986 0.3617595253545935\n"
     ]
    }
   ],
   "source": [
    "top5_b = hitrate_baseline(df_val_baseline,5)\n",
    "top10_b = hitrate_baseline(df_val_baseline,10) \n",
    "top15_b = hitrate_baseline(df_val_baseline,15) \n",
    "print(top5_b,top10_b,top15_b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
