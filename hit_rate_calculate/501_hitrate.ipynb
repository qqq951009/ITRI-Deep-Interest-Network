{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from deepctr.models import DeepFM,DIN\n",
    "from deepctr.feature_column import SparseFeat, VarLenSparseFeat, DenseFeat, get_feature_names\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import pickle\n",
    "import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def save_variable(v,filename):\n",
    "    f=open(filename,'wb')\n",
    "    pickle.dump(v,f)\n",
    "    f.close()\n",
    "    return filename\n",
    "def load_variable(filename):\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "gid_dict = load_variable('/home/jovyan/dataset/gid_dict')\n",
    "gid_list = load_variable('/home/jovyan/dataset/gid_list')#len = 1739595 4/1-4/30所有gid\n",
    "df_val = pd.read_csv('/home/jovyan/dataset/validate_folder/501val.csv')\n",
    "df_candidate = load_variable('/home/jovyan/dataset/original_candidate_itemset/0501_candidate_itemset')#len = 1422941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py:5507: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "888389\n"
     ]
    }
   ],
   "source": [
    "def clean_candidate(df):#舊方法刪完後的結果(不存在就刪掉)\n",
    "    df = df[df['gid'].isin(gid_list)]\n",
    "    df.candidate_items = df.candidate_items.apply(lambda x:x.split(','))\n",
    "    df = df.explode('candidate_items', ignore_index=True)\n",
    "    df = df[df['candidate_items'].isin(gid_list)]#推薦清單 candidate_item清掉不在4/1-4/30的商品\n",
    "    df.gid = df.gid.apply(lambda x:gid_dict[x])\n",
    "    df.candidate_items = df.candidate_items.apply(lambda x:gid_dict[x])\n",
    "    df = df.groupby(['gid']).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    df = df[df.candidate_items.apply(lambda x:len(x)) >15]\n",
    "    df = df.reset_index()\n",
    "    return df\n",
    "df_candidate = clean_candidate(df_candidate)#888389\n",
    "df_candidate['original_score'] = df_candidate.candidate_items.apply(lambda x:list(np.arange(1,0,-1/len(x))))\n",
    "print(len(df_candidate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "df5_all = load_variable('/home/jovyan/dataset/df5_all')\n",
    "df_uid = df5_all[df5_all['uid'] != 'unknow']\n",
    "df_session = df5_all[df5_all['uid'] == 'unknow']\n",
    "lbe = LabelEncoder()\n",
    "for i in ['uid']:\n",
    "    df_uid['uid_encode'] = lbe.fit_transform(df_uid[i])\n",
    "    df_uid['uid_encode'] = df_uid['uid_encode'].apply(lambda x:x+1)\n",
    "for i in ['ven_session']:\n",
    "    df_session['session_encode'] = lbe.fit_transform(df_session[i])\n",
    "    df_session['session_encode'] = df_session['session_encode'].apply(lambda x:x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid_encode_unique = df_uid[['uid','uid_encode']].sort_values('uid_encode').uid_encode.unique()\n",
    "uid_unique = df_uid[['uid','uid_encode']].sort_values('uid_encode').uid.unique()\n",
    "uid_dict = {}\n",
    "for i in zip(uid_encode_unique,uid_unique):\n",
    "    uid_dict[i[1]] = i[0]\n",
    "session_encode_unique = df_session[['ven_session','session_encode']].sort_values('session_encode').session_encode.unique()\n",
    "session_unique = df_session[['ven_session','session_encode']].sort_values('session_encode').ven_session.unique()\n",
    "session_dict = {}\n",
    "for i in zip(session_encode_unique,session_unique):\n",
    "    session_dict[i[1]] = i[0]\n",
    "session_dict[0] = 0\n",
    "uid_dict[0] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5/1 weblog\n",
    "df_uid5 = df_uid[df_uid['month'] == 51]\n",
    "df_session5 = df_session[df_session['month'] == 51]\n",
    "df_uid5.uid = df_uid5.uid.apply(lambda x:uid_dict[x])\n",
    "df_session5.ven_session = df_session5.ven_session.apply(lambda x:session_dict[x])\n",
    "df_session5 = df_session5.drop(columns = ['uid','ven_guid'])\n",
    "df_uid5 = df_uid5.drop(columns=['ven_guid','ven_session'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86663, 44174)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#處理validation set\n",
    "df_val_session = df_val[df_val.uid.isna()]\n",
    "df_val_uid = df_val[~df_val.uid.isna()]\n",
    "len(df_val_session),len(df_val_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_session.ven_session = df_val_session.ven_session.apply(lambda x:session_dict[x])\n",
    "df_val_uid.uid = df_val_uid.uid.apply(lambda x:uid_dict[x])\n",
    "df_val_session.gid = df_val_session.gid.apply(lambda x:gid_dict[x])\n",
    "df_val_uid.gid = df_val_uid.gid.apply(lambda x:gid_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "def process(df_val,df,idname):\n",
    "    hist = []\n",
    "    id_list = df_val[idname].unique().tolist()\n",
    "    for i in id_list:\n",
    "        tempdf = df[df[idname] == i]\n",
    "        tempdf_copy = df[df[idname] == i]\n",
    "        gid_list = df_val[df_val[idname] == i].gid.tolist()\n",
    "        for j in gid_list:\n",
    "            index = tempdf[tempdf.gid_encode == j].index[0]\n",
    "            tempdf = tempdf.drop(index)\n",
    "            hist.append(tempdf_copy.loc[:index].gid_encode.tolist())\n",
    "    df_val['hist'] = hist\n",
    "    return df_val\n",
    "df_val_session = process(df_val_session,df_session5,'ven_session')\n",
    "df_val_uid = process(df_val_uid,df_uid5,'uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57506 30704\n"
     ]
    }
   ],
   "source": [
    "result_session = pd.merge(df_candidate,df_val_session,how = 'inner',on = ['gid'])\n",
    "result_uid = pd.merge(df_candidate,df_val_uid,how = 'inner',on = ['gid'])\n",
    "result_session = result_session[['ven_session','gid','hist','next_gid','candidate_items','original_score']]\n",
    "result_uid = result_uid[['uid','gid','hist','next_gid','candidate_items','original_score']]\n",
    "result_session = result_session.sort_values('ven_session')\n",
    "result_uid = result_uid.sort_values('uid')\n",
    "result_session.next_gid = result_session.next_gid.apply(lambda x:gid_dict[x])\n",
    "result_uid.next_gid = result_uid.next_gid.apply(lambda x:gid_dict[x])\n",
    "result_session['flag'] = list(range(1,len(result_session)+1))\n",
    "result_uid['flag'] = list(range(1,len(result_uid)+1))\n",
    "print(len(result_session),len(result_uid)) #(62166, 32886)\n",
    "result_session_explode = result_session.explode(['candidate_items','original_score'], ignore_index=True)\n",
    "result_uid_explode = result_uid.explode(['candidate_items','original_score'], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pred_set(result):\n",
    "    pred_list = []\n",
    "    hist = 0\n",
    "    for i in zip(result['hist'].tolist(),result['candidate_items'].tolist()):\n",
    "        if len(i[0])>100:\n",
    "            pred_list.append((i[0][-100:],i[1],100))\n",
    "        else:\n",
    "            pred_list.append((i[0],i[1],len(i[0])))\n",
    "    return pred_list\n",
    "pred_set_session = create_pred_set(result_session_explode)\n",
    "pred_set_uid = create_pred_set(result_uid_explode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predict_array(pred_set):\n",
    "    hist_g_id = []\n",
    "    g_id = []\n",
    "    seq_length = []\n",
    "    for index, value in enumerate(pred_set):\n",
    "        hist_g_id.append(value[0]) \n",
    "        g_id.append(value[1])\n",
    "        seq_length.append(value[2])\n",
    "    for i in range(len(hist_g_id)):\n",
    "        if len(hist_g_id[i]) < 100:\n",
    "            hist_g_id[i] += (100-len(hist_g_id[i]))*[0]\n",
    "    g_id = np.array(g_id)\n",
    "    hist_g_id = np.array(hist_g_id)\n",
    "    seq_length = np.array(seq_length)\n",
    "    return hist_g_id, g_id, seq_length\n",
    "\n",
    "hist_gid_session, gid_session, seq_length_session = create_predict_array(pred_set_session)\n",
    "hist_gid_uid, gid_uid, seq_length_uid = create_predict_array(pred_set_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1558159, 1440136, 1306514, ...,       0,       0,       0],\n",
       "        [1558159, 1440136, 1306514, ...,       0,       0,       0],\n",
       "        [1558159, 1440136, 1306514, ...,       0,       0,       0],\n",
       "        ...,\n",
       "        [ 436025, 1823671,  168780, ...,       0,       0,       0],\n",
       "        [ 436025, 1823671,  168780, ...,       0,       0,       0],\n",
       "        [ 436025, 1823671,  168780, ...,       0,       0,       0]]),\n",
       " array([ 850896,  657317, 1131201, ..., 1386389,  247779,  281951]),\n",
       " array([7, 7, 7, ..., 9, 9, 9]))"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_gid_session, gid_session, seq_length_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_uid_pred = {'g_id': gid_uid, \n",
    "        'hist_g_id': hist_gid_uid, \n",
    "        'seq_length': seq_length_uid}\n",
    "x_session_pred = {'g_id': gid_session, \n",
    "        'hist_g_id': hist_gid_session, \n",
    "        'seq_length': seq_length_session}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/1-4/30 predict 5/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"/home/jovyan/dataset/rakuten_model_401_430\")\n",
    "y_uid = model.predict(x_uid_pred)\n",
    "y_session = model.predict(x_session_pred)\n",
    "y_uid = y_uid.reshape(-1).tolist()\n",
    "y_session = y_session.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_uid_explode['score'] = y_uid\n",
    "result_session_explode['score'] = y_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_new_score(result):\n",
    "    new_score = []\n",
    "    for i in result.iterrows():\n",
    "        new_score.append(0.2*(i[1]['score'])+0.8*(i[1]['original_score']))\n",
    "    result['new_score'] = new_score\n",
    "    result = result.sort_values(['flag','new_score'],ascending = False)\n",
    "    df_output = result.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    return df_output\n",
    "df1 = cal_new_score(result_uid_explode)\n",
    "df2 = cal_new_score(result_session_explode)\n",
    "resultdf = pd.concat([df1,df2],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag</th>\n",
       "      <th>gid</th>\n",
       "      <th>next_gid</th>\n",
       "      <th>candidate_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>376598</td>\n",
       "      <td>1159738</td>\n",
       "      <td>[620948, 586330, 480667, 329244, 873541, 11230...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>379427</td>\n",
       "      <td>1080258</td>\n",
       "      <td>[379679, 1867193, 770807, 379930, 379149, 1178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>379427</td>\n",
       "      <td>1080258</td>\n",
       "      <td>[379679, 1867193, 379930, 770807, 379149, 1178...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>970790</td>\n",
       "      <td>970279</td>\n",
       "      <td>[1186926, 379149, 1178763, 379427, 1182338, 18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1197610</td>\n",
       "      <td>1784240</td>\n",
       "      <td>[505071, 1267022, 1052775, 1741730, 833471, 14...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flag      gid  next_gid                                    candidate_items\n",
       "0     1   376598   1159738  [620948, 586330, 480667, 329244, 873541, 11230...\n",
       "1     2   379427   1080258  [379679, 1867193, 770807, 379930, 379149, 1178...\n",
       "2     3   379427   1080258  [379679, 1867193, 379930, 770807, 379149, 1178...\n",
       "3     4   970790    970279  [1186926, 379149, 1178763, 379427, 1182338, 18...\n",
       "4     5  1197610   1784240  [505071, 1267022, 1052775, 1741730, 833471, 14..."
      ]
     },
     "execution_count": 628,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25243169708649815 0.33468994445074257 0.37912935041378526\n"
     ]
    }
   ],
   "source": [
    "def hitrate(result,k):\n",
    "    count = 0\n",
    "    for i in result.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count+=1\n",
    "    return count/len(result)\n",
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoch15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DIN(feature_columns, behavior_feature_list)\n",
    "model.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/15epoch/model401_430\")\n",
    "model.load_weights(latest)\n",
    "\n",
    "y_uid = model.predict(x_uid_pred)\n",
    "y_session = model.predict(x_session_pred)\n",
    "y_uid = y_uid.reshape(-1).tolist()\n",
    "y_session = y_session.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid\n",
    "result_session_explode['score'] = y_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "0.15461965763518876 0.2494501757170389 0.3212220836639837\n"
     ]
    }
   ],
   "source": [
    "epoch15_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df1 = epoch15_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df2 = epoch15_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df = pd.concat([epoch15_df1,epoch15_df2],ignore_index=True)\n",
    "top5 = hitrate(epoch15_df,5)\n",
    "top10 = hitrate(epoch15_df,10)\n",
    "top15 = hitrate(epoch15_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4/1-5/1 model predict 5/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior_feature_list = [\"g_id\"]\n",
    "feature_columns = [SparseFeat('g_id', 1870599, embedding_dim=8)]\n",
    "feature_columns += [VarLenSparseFeat(SparseFeat('hist_g_id',vocabulary_size=1870599, embedding_dim=8, embedding_name='g_id'), maxlen = 100, length_name='seq_length')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f58d8613358>"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model501 = DIN(feature_columns, behavior_feature_list)\n",
    "model501.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/checkpoint_folder/model_401_501\")\n",
    "model501.load_weights(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_uid51 = model501.predict(x_uid_pred)\n",
    "y_session51 = model501.predict(x_session_pred)\n",
    "y_uid51 = y_uid51.reshape(-1).tolist()\n",
    "y_session51 = y_session51.reshape(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_uid_explode['score'] = y_uid51\n",
    "result_session_explode['score'] = y_session51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_new_score(result):\n",
    "    new_score = []\n",
    "    for i in result.iterrows():\n",
    "        new_score.append(0.2*(i[1]['score'])+0.8*(i[1]['original_score']))\n",
    "    result['new_score'] = new_score\n",
    "    result = result.sort_values(['flag','new_score'],ascending = False)\n",
    "    df_output = result.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "    return df_output\n",
    "df3 = cal_new_score(result_uid_explode)\n",
    "df4 = cal_new_score(result_session_explode)\n",
    "resultdf = pd.concat([df3,df4],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25904092506518533 0.33899784604920075 0.3821335449495522\n"
     ]
    }
   ],
   "source": [
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.26725994785171747 0.3465480104296565 0.38848203151570115\n"
     ]
    }
   ],
   "source": [
    "def hitrate(result,k):\n",
    "    count = 0\n",
    "    for i in result.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count+=1\n",
    "    return count/len(result)\n",
    "top5 = hitrate(resultdf,5)\n",
    "top10 = hitrate(resultdf,10)\n",
    "top15 = hitrate(resultdf,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15epoch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model501 = DIN(feature_columns, behavior_feature_list)\n",
    "model501.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/15epoch/model401_501\")\n",
    "model501.load_weights(latest)\n",
    "\n",
    "y_uid15 = model501.predict(x_uid_pred)\n",
    "y_session15 = model501.predict(x_session_pred)\n",
    "y_uid15 = y_uid15.reshape(-1).tolist()\n",
    "y_session15 = y_session15.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid15\n",
    "result_session_explode['score'] = y_session15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23860106563881647 0.3311642670898991 0.3794127649926312\n"
     ]
    }
   ],
   "source": [
    "epoch15_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch15_df1 = epoch15_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df2 = epoch15_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch15_df = pd.concat([epoch15_df1,epoch15_df2],ignore_index=True)\n",
    "top5 = hitrate(epoch15_df,5)\n",
    "top10 = hitrate(epoch15_df,10)\n",
    "top15 = hitrate(epoch15_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20epoch predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.momentum\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n"
     ]
    }
   ],
   "source": [
    "model501 = DIN(feature_columns, behavior_feature_list)\n",
    "model501.compile('SGD', 'binary_crossentropy',metrics=['accuracy','AUC'])\n",
    "latest = tf.train.latest_checkpoint(\"/home/jovyan/dataset/20epoch/model401_501\")\n",
    "model501.load_weights(latest)\n",
    "\n",
    "y_uid20 = model501.predict(x_uid_pred)\n",
    "y_session20 = model501.predict(x_session_pred)\n",
    "y_uid20 = y_uid20.reshape(-1).tolist()\n",
    "y_session20 = y_session20.reshape(-1).tolist()\n",
    "result_uid_explode['score'] = y_uid20\n",
    "result_session_explode['score'] = y_session20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24710350300419454 0.3340210860446661 0.3803763745607074\n"
     ]
    }
   ],
   "source": [
    "epoch20_df1 = result_uid_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df2 = result_session_explode.sort_values(['flag','score'],ascending = False)\n",
    "epoch20_df1 = epoch20_df1.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df2 = epoch20_df2.groupby(['flag','gid','next_gid'],as_index=False).agg({'candidate_items': lambda x: x.tolist()})\n",
    "epoch20_df = pd.concat([epoch20_df1,epoch20_df2],ignore_index=True)\n",
    "\n",
    "top5 = hitrate(epoch20_df,5)\n",
    "top10 = hitrate(epoch20_df,10)\n",
    "top15 = hitrate(epoch20_df,15)\n",
    "print(top5,top10,top15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val1 = df_val_session[df_val_session.gid.isin(df_candidate.gid.tolist())]\n",
    "df_val2 = df_val_uid[df_val_uid.gid.isin(df_candidate.gid.tolist())]\n",
    "df_val_baseline =  pd.concat([df_val1,df_val2],ignore_index=True)\n",
    "df_val_baseline.next_gid = df_val_baseline.next_gid.apply(lambda x:gid_dict[x])\n",
    "df_val_baseline = pd.merge(df_candidate,df_val_baseline,how = 'inner',on = ['gid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hitrate_baseline(df,k):\n",
    "    count = 0\n",
    "    for i in df.iterrows():\n",
    "        if i[1]['next_gid'] in i[1]['candidate_items'][:k]:\n",
    "            count += 1 \n",
    "    return count/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88210\n",
      "88210\n",
      "88210\n",
      "0.23506405169481917 0.3238861807051355 0.3722367078562521\n"
     ]
    }
   ],
   "source": [
    "top5_b = hitrate_baseline(df_val_baseline,5)\n",
    "top10_b = hitrate_baseline(df_val_baseline,10) \n",
    "top15_b = hitrate_baseline(df_val_baseline,15) \n",
    "print(top5_b,top10_b,top15_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hit rate request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1664477, 1481235, 1304276, 1131201, 1011203, 1009285, 1008531, 924358, 879259, 850896, 792107, 657317, 464796, 433591, 422857, 212779, 189516, 121674, 92056]]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "API_ENDPOINT = \"http://localhost:5000/\"\n",
    "x_request = {\n",
    "            'hist_g_id':input1,\n",
    "            'candidate':input2,\n",
    "            'seq_length':input3\n",
    "            #'candidate_len':candidate_len\n",
    "            }\n",
    "r = requests.post(url=API_ENDPOINT, json=x_request)\n",
    "#print(r.text)\n",
    "r = r.json()\n",
    "print(r['rerank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = result_session['hist'][-2000:].tolist()\n",
    "input2 = result_session['candidate_items'][-2000:].tolist()\n",
    "input3 = result_session['hist'][-2000:].apply(lambda x:100-x.count(0)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost 185.7854290008545 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "API_ENDPOINT = \"http://localhost:5000/\"\n",
    "time_start = time.time()\n",
    "for i in zip(input1,input2,input3):\n",
    "    x_request = {\n",
    "            'hist_g_id':i[0],\n",
    "            'candidate':i[1],\n",
    "            'seq_length':i[2]\n",
    "            }\n",
    "    r = requests.post(url=API_ENDPOINT, json=x_request)\n",
    "    #r = r.json()\n",
    "    #print(r['rerank'])\n",
    "time_end = time.time()    \n",
    "time_c= time_end - time_start  \n",
    "print('time cost', time_c, 's')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
